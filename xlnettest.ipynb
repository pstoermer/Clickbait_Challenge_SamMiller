{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esser\\.virtualenvs\\anlp-Bd8LEaH2\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, XLNetTokenizer\n",
    "import torch\n",
    "from keras.utils import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/validation.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'multi', 1: 'passage', 2: 'phrase'}\n",
      "[-0.09633252 -0.51153016  0.5233277 ]\n",
      "[-0.6206944  1.0529232 -0.4994568]\n",
      "[ 0.36697555 -1.4582872   1.5293717 ]\n",
      "[ 0.8836718 -2.0157027  1.3445599]\n",
      "[-0.8933996  1.4569148 -0.4938417]\n",
      "[-0.99288833 -0.9207619   2.3369708 ]\n",
      "[-1.0384986  -0.35779676  1.8897498 ]\n",
      "[-0.959985    0.9579983  -0.18352915]\n",
      "[-1.4583246   1.7873356  -0.07945199]\n",
      "[-1.1699524   1.384661    0.04090883]\n",
      "[ 1.0335108   0.16628508 -1.5101539 ]\n",
      "[-0.45465112 -1.0087416   2.2786796 ]\n",
      "[ 0.6076848   0.08860607 -1.0492194 ]\n",
      "[-1.411865  -0.0073873  1.5171795]\n",
      "[-0.29710814 -1.1043086   1.9408407 ]\n",
      "[-0.39609197  1.4887915  -0.8675545 ]\n",
      "[-1.0495147  2.2483516 -0.9245384]\n",
      "[-1.0066575   1.0645547   0.02053583]\n",
      "[-0.5648729   0.74463284 -0.13506268]\n",
      "[-1.446449   1.0170202  0.3164273]\n",
      "[-0.7640938  1.3005023 -0.3515777]\n",
      "[-1.1252096  2.2595196 -1.0287063]\n",
      "[-0.9374156  1.9168053 -0.8453071]\n",
      "[-0.57325613  0.9862334  -0.344638  ]\n",
      "[-1.4634087   1.6417038  -0.06321429]\n",
      "[ 0.44460148 -1.2835959   1.3778563 ]\n",
      "[ 2.031961   -2.267418    0.50733304]\n",
      "[ 1.9546671  -1.4870081  -0.59243536]\n",
      "[-0.19649962  1.3344845  -1.0370141 ]\n",
      "[-0.19214073 -1.1586938   1.8391376 ]\n",
      "[-1.6375291  0.9649327  0.939192 ]\n",
      "[ 0.42393976 -1.2038327   1.5106008 ]\n",
      "[ 0.3337468 -1.6767869  1.9474573]\n",
      "[-0.5540767 -1.1629696  2.302248 ]\n",
      "[ 0.4868913  0.5252936 -0.9069699]\n",
      "[-0.59320843  1.0812821  -0.30139166]\n",
      "[-0.1207733 -0.7563172  1.3075302]\n",
      "[ 3.4734268 -2.8747838 -2.0295691]\n",
      "[-0.563326   1.3328547 -0.4376107]\n",
      "[-0.9219083   0.02209271  1.2166114 ]\n",
      "[ 3.5495439 -2.8331378 -2.4200509]\n",
      "[-0.25539196  1.2825476  -1.1104499 ]\n",
      "[-0.9642814   0.20054527  1.2924274 ]\n",
      "[-0.537506  -0.9522179  1.7015995]\n",
      "[-1.4747896  -0.31470245  1.7991675 ]\n",
      "[-1.1338949   1.4460504  -0.35986218]\n",
      "[ 1.5204374  -1.4225338  -0.05091488]\n",
      "[-0.74883604  1.0561662  -0.4509809 ]\n",
      "[-0.22882646 -1.290582    2.0925813 ]\n",
      "[-1.1466087  1.8097793 -0.7396655]\n",
      "[-1.4668901   1.6237295  -0.20436767]\n",
      "[-0.14070924  0.97582054 -0.6379458 ]\n",
      "[-0.75076485 -1.2229093   2.4542732 ]\n",
      "[-0.4646708 -1.5212269  2.7655838]\n",
      "[-0.46869183  0.51329565 -0.01597691]\n",
      "[-0.7071075  2.0296323 -1.3013914]\n",
      "[-1.0850267  -0.01257735  0.99600875]\n",
      "[-1.041497  -0.0744195  1.3318703]\n",
      "[ 0.2803353  0.9194898 -1.1596812]\n",
      "[-0.6560708 -1.2028441  2.2448936]\n",
      "[-0.16574776 -0.8414401   1.3502302 ]\n",
      "[-1.0105772   1.1825399   0.02761419]\n",
      "[ 1.2498494  -0.05040173 -1.1634932 ]\n",
      "[-0.26971  -0.645889  1.336344]\n",
      "[ 0.04351666  0.59286165 -0.66935307]\n",
      "[-0.3737584 -1.3189296  2.3067634]\n",
      "[-0.619436   1.6380073 -0.9561828]\n",
      "[-0.57825464  0.91959316 -0.44252   ]\n",
      "[-0.81310374 -1.2897266   2.6683877 ]\n",
      "[-0.05856297 -1.293659    1.7352712 ]\n",
      "[ 1.3612113   0.36782652 -1.7588103 ]\n",
      "[-0.79086566  1.4977586  -0.6795715 ]\n",
      "[-0.3130126 -1.305011   2.258094 ]\n",
      "[-1.0962304  2.463674  -0.9636167]\n",
      "[ 0.22492464 -0.5882162   0.44268185]\n",
      "[-0.36368808 -1.1699064   2.3499656 ]\n",
      "[-0.2837008 -1.0333776  1.9071217]\n",
      "[-1.8206944   0.64965004  1.4140284 ]\n",
      "[-4.4420362e-05  1.1548339e+00 -1.0321637e+00]\n",
      "[-0.54305404 -1.4873421   2.8807602 ]\n",
      "[ 0.30572265 -1.2759953   1.2138386 ]\n",
      "[ 0.1222679   0.91831845 -1.2974827 ]\n",
      "[-1.4051862   2.120681   -0.59145546]\n",
      "[ 0.03634321 -1.7147796   2.1543756 ]\n",
      "[ 0.56051004  0.2879513  -0.996426  ]\n",
      "[-0.79836273  1.785909   -0.98075235]\n",
      "[-0.24943064  0.9909504  -0.6222132 ]\n",
      "[-0.48015144  1.079503   -0.57681334]\n",
      "[-1.7340431   1.5466768   0.22435589]\n",
      "[-1.8802383   1.4972003   0.30584115]\n",
      "[ 0.9157541  -0.1872288  -0.90006936]\n",
      "[ 2.7274437 -2.542811  -1.0075235]\n",
      "[-0.80898917  0.96180403 -0.00260115]\n",
      "[-0.35780445  0.17211066  0.17663813]\n",
      "[-0.33012182 -1.3065159   2.3510375 ]\n",
      "[-0.7803572   0.5294197   0.24496508]\n",
      "[-0.7574847 -0.8810567  2.4336767]\n",
      "[-0.9595456  1.7833008 -0.7612253]\n",
      "[-1.3019779  -0.01688914  1.650709  ]\n",
      "[-0.81133735  1.3291163  -0.56575894]\n",
      "[ 0.46334207 -1.4071372   1.597009  ]\n",
      "[-0.7935129   0.7551162   0.08875175]\n",
      "[-1.7721055  1.3317853  0.6533115]\n",
      "[-0.74135846 -0.50444126  1.2296851 ]\n",
      "[ 0.1700575 -1.2849405  1.4247327]\n",
      "[-1.1417091  1.8147569 -0.5393512]\n",
      "[-0.8251586   0.9781281  -0.12847784]\n",
      "[ 0.28438675 -0.67110264  1.0843723 ]\n",
      "[ 3.0519109 -2.3262677 -2.7359574]\n",
      "[-0.23588835  0.85535574 -0.5020059 ]\n",
      "[ 1.9703087 -1.3353758 -0.670678 ]\n",
      "[ 3.711723  -2.5171936 -2.2756221]\n"
     ]
    }
   ],
   "source": [
    "true_labels = list(df['tags'])\n",
    "true_labels = [item for sublist in true_labels for item in sublist]\n",
    "uuids = list(df['uuid'])\n",
    "decoding_array = {  \n",
    "            0 : \"multi\",\n",
    "            1: \"passage\",\n",
    "            2 : \"phrase\"\n",
    "            }\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"EstrixDS/XLNet_SemEval_Task1\")\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
    "# Create sentence and label lists\n",
    "sentences = df['postText'].values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for XLNet to work properly\n",
    "sentences = [sentence[0] + \" [SEP] [CLS]\" for sentence in sentences]\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "\n",
    "MAX_LEN = 256\n",
    "# Use the XLNet tokenizer to convert the tokens to their index numbers in the XLNet vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) \n",
    "\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "# Prediction on test set\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions = []\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    for i in logits:\n",
    "        predictions.append(i)\n",
    "decoded_pred = []\n",
    "for z in predictions:\n",
    "    label = np.where(z == z.max())\n",
    "    decoded_label = decoding_array[label[0][0]]\n",
    "    decoded_pred.append(decoded_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7452153110047847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bac = balanced_accuracy_score(y_true=true_labels,y_pred=decoded_pred)\n",
    "print(bac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6434106524853385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "mc = matthews_corrcoef(y_true=true_labels,y_pred=decoded_pred)\n",
    "print(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6245858257095941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "jac = jaccard_score(y_true=true_labels,y_pred=decoded_pred,average='weighted')\n",
    "print(jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       multi       0.87      0.59      0.70        22\n",
      "     passage       0.65      0.89      0.76        38\n",
      "      phrase       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.77       112\n",
      "   macro avg       0.80      0.75      0.75       112\n",
      "weighted avg       0.79      0.77      0.77       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "rep = classification_report(y_true=true_labels,y_pred=decoded_pred)\n",
    "print(rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('anlp-Bd8LEaH2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "941b07e373631be7fd8257c1dcac349d04aaa134546f10f2da895e506c065c0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
